<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="kafka-producer-model"><meta name="keywords" content="kafka"><meta name="author" content="leiline"><meta name="copyright" content="leiline"><title>kafka-producer-model | 李林林的精神驿站</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka消息队列结构"><span class="toc-number">1.</span> <span class="toc-text">kafka消息队列结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka名词解释"><span class="toc-number">2.</span> <span class="toc-text">kafka名词解释</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">leiline</div><div class="author-info__description text-center">知道你要去很远的地方，但请一定记得回头看看</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">39</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">20</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">3</span></a></div></div></div><div id="content-outer"><div class="plain" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">李林林的精神驿站</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">首页</a><a class="site-page" href="/categories/technology">技艺</a><a class="site-page" href="/categories/life">生活</a><a class="site-page" href="/categories/others">其他</a><a class="site-page" href="/about">关于</a><a class="site-page" href="/archives">归档</a></span></div></div><div class="layout" id="content-inner"><article id="post"><div class="plain" id="post-title">kafka-producer-model</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-15</time></div><div class="article-container" id="post-content"><p>阅读了一下kafka的源代码，总结producer端做的事情。</p>
<a id="more"></a>

<p>kafka 是目前性能最好的分布式消息系统，具有高吞吐，低延迟的特性，被很多开发者所使用。</p>
<h2 id="kafka消息队列结构"><a href="#kafka消息队列结构" class="headerlink" title="kafka消息队列结构"></a>kafka消息队列结构</h2><p>kafka采用消息订阅-发布的模式架构，角色有两种：生产者(producer)和消费者(consumer)。生产者负责生产数据，消费者负责消费数据。生产者将产生的数据发送到topic中，消费者则从topic中提取数据。</p>
<img src="/images/kafka-constuctor.JPG">

<p>topic实现了消息的订阅与发布，一个或多个producer可以往topic中发送数据，一个或多个cZonsumer可以从topic中获取数据，这样就实现了消息传输的负载均衡。</p>
<h2 id="kafka名词解释"><a href="#kafka名词解释" class="headerlink" title="kafka名词解释"></a>kafka名词解释</h2><p>kafka中有一些专有词汇，解释一下方便理解。</p>
<ul>
<li><p><strong>producer ：</strong> 消息生产者，就是向kafka broker发消息的客户端。</p>
</li>
<li><p><strong>Consumer ：</strong> 消息消费者，向kafka broker取消息的客户端</p>
</li>
<li><p><strong>Topic ：</strong> 可以理解为一个队列。</p>
</li>
<li><p><strong>Consumer Group （CG）：</strong> 这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个CG只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。</p>
</li>
<li><p><strong>Broker ：</strong>  一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</p>
</li>
<li><p><strong>Partition：</strong> 为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。</p>
</li>
<li><p><strong>Offset：</strong> 偏移量，kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka</p>
</li>
</ul>
<p>为了研究kafka源码，我们从producer往topic中发送数据的流程开始研究。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String topic, Boolean isAsync)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, KafkaProperties.KAFKA_SERVER_URL + <span class="string">":"</span> + KafkaProperties.KAFKA_SERVER_PORT);</span><br><span class="line">        props.put(<span class="string">"client.id"</span>, <span class="string">"DemoProducer"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.IntegerSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        <span class="keyword">this</span>.isAsync = isAsync;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> messageNo = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            String messageStr = <span class="string">"Message_"</span> + messageNo;</span><br><span class="line">            <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">if</span> (isAsync) &#123; <span class="comment">// Send asynchronously</span></span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(topic,</span><br><span class="line">                    messageNo,</span><br><span class="line">                    messageStr), <span class="keyword">new</span> DemoCallBack(startTime, messageNo, messageStr));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">// Send synchronously</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(topic,</span><br><span class="line">                        messageNo,</span><br><span class="line">                        messageStr)).get();</span><br><span class="line">                    System.out.println(<span class="string">"Sent message: ("</span> + messageNo + <span class="string">", "</span> + messageStr + <span class="string">")"</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            ++messageNo;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>往topic发送数据主要有两步，首先要填写一些配置信息，包括bootstrap.servers， topic等，然后进入run()方法，通过send()将数据进行发送。可以看到数据的对象是ProducerRecord。查看ProducerRecord的定义，发现它主要有5个属性，包含topic, partition数量，k, v, 以及时间戳。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, Integer partition, Long timestamp, K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (topic == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Topic cannot be null."</span>);</span><br><span class="line">        <span class="keyword">if</span> (timestamp != <span class="keyword">null</span> &amp;&amp; timestamp &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    String.format(<span class="string">"Invalid timestamp: %d. Timestamp should always be non-negative or null."</span>, timestamp));</span><br><span class="line">        <span class="keyword">if</span> (partition != <span class="keyword">null</span> &amp;&amp; partition &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">                    String.format(<span class="string">"Invalid partition: %d. Partition number should always be non-negative or null."</span>, partition));</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        <span class="keyword">this</span>.partition = partition;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.timestamp = timestamp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在send()方法中，将数据传入到doSend()方法中，进行真正的数据发送工作。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? record : <span class="keyword">this</span>.interceptors.onSend(record);</span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在往topic中发送数据前先要进行几项工作：</p>
<ol>
<li>查看topic的metadata是否可用。metadata记录了topic的状态信息，</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> TOPIC_EXPIRY_MS = <span class="number">5</span> * <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> TOPIC_EXPIRY_NEEDS_UPDATE = -<span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> refreshBackoffMs;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> metadataExpireMs;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> version;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">long</span> lastRefreshMs;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">long</span> lastSuccessfulRefreshMs;</span><br><span class="line">   <span class="keyword">private</span> Cluster cluster;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">boolean</span> needUpdate;</span><br><span class="line">   <span class="comment">/* Topics with expiry time */</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Long&gt; topics;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> List&lt;Listener&gt; listeners;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> ClusterResourceListeners clusterResourceListeners;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">boolean</span> needMetadataForAllTopics;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> topicExpiryEnabled;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>进行序列化操作</p>
</li>
<li><p>获取record的partition的值。</p>
<blockquote>
<pre><code>partition的值有三种计算方式：</code></pre><p>   1） 在指明partition的情况下，直接将指明的值作为partition的值<br>   2） 没有指明partition但是有key值的时候，将key的hash与topic的partition数进行取余得到partition值<br>   3） 既没有partition也没有key值的时候，第一次调用随机生成一个整数，将这个值与topic可用的Partition总数取余得到partition值，即round-robin算法。</p>
</blockquote>
</li>
<li><p>检查record是否超过了内存大小，是否超过字段最大要求</p>
</li>
<li><p>将record加入到队列中。（这一步才是真正开始发送数据）</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">        TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">            ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">            <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">            Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">            <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                serializedKey = keySerializer.serialize(record.topic(), record.key());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert key of class "</span> + record.key().getClass().getName() +</span><br><span class="line">                        <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                        <span class="string">" specified in key.serializer"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                serializedValue = valueSerializer.serialize(record.topic(), record.value());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert value of class "</span> + record.value().getClass().getName() +</span><br><span class="line">                        <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                        <span class="string">" specified in value.serializer"</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">            <span class="keyword">int</span> serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);</span><br><span class="line">            ensureValidRecordSize(serializedSize);</span><br><span class="line">            tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line">            <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">            log.trace(<span class="string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);</span><br><span class="line">            <span class="comment">// producer callback will make sure to call both 'callback' and interceptor callback</span></span><br><span class="line">            Callback interceptCallback = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? callback : <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line">            RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);</span><br><span class="line">            <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">                log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">                <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> result.future;</span><br><span class="line">            <span class="comment">// handling exceptions and record the errors;</span></span><br><span class="line">            <span class="comment">// for API exceptions return them in the future,</span></span><br><span class="line">            <span class="comment">// for other exceptions throw directly</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (ApiException e) &#123;</span><br><span class="line">            log.debug(<span class="string">"Exception occurred during message send:"</span>, e);</span><br><span class="line">            <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</span><br><span class="line">                callback.onCompletion(<span class="keyword">null</span>, e);</span><br><span class="line">            <span class="keyword">this</span>.errors.record();</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> FutureFailure(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">this</span>.errors.record();</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> InterruptException(e);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BufferExhaustedException e) &#123;</span><br><span class="line">            <span class="keyword">this</span>.errors.record();</span><br><span class="line">            <span class="keyword">this</span>.metrics.sensor(<span class="string">"buffer-exhausted-records"</span>).record();</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">            <span class="keyword">this</span>.errors.record();</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// we notify interceptor about all exceptions, since onSend is called before anything else in this method</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>producer采用批量发送的策略，首先先将数据加入RecordAccumulator队列，等到result.batchIsFull 或者 result.newBatchCreated时则唤醒发送客户端进行数据发送。batchSize是由用户填写的配置确定的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">    log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">    <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>RecordAccumulator 模型如图所示，每一个topicPartition都会对应一个Deque<recordbatch>，当数据加入时，topicPartition对应的Deque会创建的RecordBatch加入record，当发送数据时，则从最老的RecordBatch开始发送。</recordbatch></p>
<img src="/images/recordbatch.JPG">

<p>数据写入的流程如下图所示</p>
<img src="/images/sender.JPG">

<p>sender的写入过程是在run()方法中进行的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">        Cluster cluster = metadata.fetch();</span><br><span class="line">        <span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">        RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// if there are any partitions whose leaders are not known yet, force metadata update</span></span><br><span class="line">        <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">// The set of topics with unknown leader contains topics with leader election pending as well as</span></span><br><span class="line">            <span class="comment">// topics which may have expired. Add the topic again to metadata to ensure it is included</span></span><br><span class="line">            <span class="comment">// and request metadata update, since there are messages to send to the topic.</span></span><br><span class="line">            <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</span><br><span class="line">                <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// remove any nodes we aren't ready to send to</span></span><br><span class="line">        Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">        <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            Node node = iter.next();</span><br><span class="line">            <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">                iter.remove();</span><br><span class="line">                notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create produce requests</span></span><br><span class="line">        Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster,</span><br><span class="line">                                                                         result.readyNodes,</span><br><span class="line">                                                                         <span class="keyword">this</span>.maxRequestSize,</span><br><span class="line">                                                                         now);</span><br><span class="line">        <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">            <span class="comment">// Mute all the partitions drained</span></span><br><span class="line">            <span class="keyword">for</span> (List&lt;RecordBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">                <span class="keyword">for</span> (RecordBatch batch : batchList)</span><br><span class="line">                    <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        List&lt;RecordBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.abortExpiredBatches(<span class="keyword">this</span>.requestTimeout, now);</span><br><span class="line">        <span class="comment">// update sensors</span></span><br><span class="line">        <span class="keyword">for</span> (RecordBatch expiredBatch : expiredBatches)</span><br><span class="line">            <span class="keyword">this</span>.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);</span><br><span class="line"></span><br><span class="line">        sensors.updateProduceRequestMetrics(batches);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately</span></span><br><span class="line">        <span class="comment">// loop and try sending more data. Otherwise, the timeout is determined by nodes that have partitions with data</span></span><br><span class="line">        <span class="comment">// that isn't yet sendable (e.g. lingering, backing off). Note that this specifically does not include nodes</span></span><br><span class="line">        <span class="comment">// with sendable data that aren't ready to send since they would cause busy looping.</span></span><br><span class="line">        <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">        <span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</span><br><span class="line">            log.trace(<span class="string">"Nodes with data ready to send: &#123;&#125;"</span>, result.readyNodes);</span><br><span class="line">            pollTimeout = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        sendProduceRequests(batches, now);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// if some partitions are already ready to be sent, the select time would be 0;</span></span><br><span class="line">        <span class="comment">// otherwise if some partition already has some data accumulated but not ready yet,</span></span><br><span class="line">        <span class="comment">// the select time will be the time difference between now and its linger expiry time;</span></span><br><span class="line">        <span class="comment">// otherwise the select time will be the time difference between now and the metadata expiry time;</span></span><br><span class="line">        <span class="keyword">this</span>.client.poll(pollTimeout, now);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>在发送数据前做了很多其他的准备验证操作。首先去metadata中获取集群信息，包括nodes,topics以及partition；然后将partition的leader是未知的强制加入到metadata中；剔除掉挂的Node；建立发送连接；返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 node.id）,并将 RecordBatch 从对应的 queue 中移除将由于元数据不可用而导致发送超时的 RecordBatch 移除；</p>
<p>最后发送数据执行的方法是sendProduceRequests()，该方法的详细内容如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;RecordBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">	Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line">	<span class="keyword">final</span> Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</span><br><span class="line">	<span class="keyword">for</span> (RecordBatch batch : batches) &#123;</span><br><span class="line">		TopicPartition tp = batch.topicPartition;</span><br><span class="line">		produceRecordsByPartition.put(tp, batch.records());</span><br><span class="line">		recordsByPartition.put(tp, batch);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	ProduceRequest.Builder requestBuilder =</span><br><span class="line">	<span class="keyword">new</span> ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);</span><br><span class="line">	RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</span><br><span class="line">			handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	String nodeId = Integer.toString(destination);</span><br><span class="line">	ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>, callback);</span><br><span class="line">	client.send(clientRequest, now);</span><br><span class="line">	log.trace(<span class="string">"Sent produce request to &#123;&#125;: &#123;&#125;"</span>, nodeId, requestBuilder);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>sendProduceRequest将nodeId相同的数据放在一起一起发送。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">leiline</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2018/09/15/kafka-producer-model/">http://yoursite.com/2018/09/15/kafka-producer-model/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/11/15/deliver/"><i class="fa fa-chevron-left">  </i><span>我做快递员的那段时光</span></a></div><div class="next-post pull-right"><a href="/2018/09/02/hyper-fabric-frist/"><span>hyper fabric 运行第一个例子</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By leiline</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>